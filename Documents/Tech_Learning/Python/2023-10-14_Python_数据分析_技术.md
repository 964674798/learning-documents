# Python数据分析

## Overview
Python已成为数据分析领域的主流语言，凭借其简洁的语法、丰富的库和活跃的社区生态，为数据科学家和分析师提供了强大的工具集。本文档记录了Python数据分析的核心技术、库和常见用例，作为个人学习和实践的参考。

## 核心库

### NumPy
NumPy是Python数据分析的基础库，提供高性能的多维数组对象和处理这些数组的工具。

```python
import numpy as np

# 创建数组
arr = np.array([1, 2, 3, 4, 5])
matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

# 数组操作
print(arr.shape)  # (5,)
print(matrix.shape)  # (3, 3)
print(arr.dtype)  # int64

# 数组计算
print(arr.sum())  # 15
print(arr.mean())  # 3.0
print(matrix.T)  # 转置矩阵

# 广播操作
print(arr + 10)  # [11 12 13 14 15]

# 数组切片
print(arr[1:4])  # [2 3 4]
print(matrix[0:2, 1:3])  # [[2 3], [5 6]]

# 生成数组
zeros = np.zeros((3, 4))  # 3x4的零矩阵
ones = np.ones((2, 3))  # 2x3的1矩阵
rng = np.random.default_rng(42)
random_array = rng.random((2, 2))  # 2x2的随机矩阵
```

### Pandas
Pandas提供了DataFrame和Series数据结构，非常适合处理表格和时间序列数据。

```python
import pandas as pd
import numpy as np

# 创建Series
s = pd.Series([1, 3, 5, np.nan, 6, 8])
print(s)

# 创建DataFrame
dates = pd.date_range('20230101', periods=6)
df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))
print(df)

# 从CSV文件加载数据
# df = pd.read_csv('file.csv')

# 查看基本信息
print(df.head())  # 前5行
print(df.describe())  # 统计摘要
print(df.info())  # 数据类型和缺失值信息

# 数据选择
print(df['A'])  # 选择单列
print(df[0:3])  # 选择行
print(df.loc[dates[0]])  # 按标签选择
print(df.iloc[3:5, 0:2])  # 按位置选择

# 数据过滤
print(df[df.A > 0])  # 条件过滤

# 数据操作
df['E'] = df['A'] + df['B']  # 新增列
df = df.drop('E', axis=1)  # 删除列
df = df.dropna()  # 删除缺失值
df = df.fillna(value=0)  # 填充缺失值

# 数据聚合
print(df.groupby('A').sum())  # 分组聚合
print(df.pivot_table(values='D', index=['A', 'B'], columns='C'))  # 透视表

# 时间序列处理
ts = pd.Series(np.random.randn(1000), index=pd.date_range('20230101', periods=1000))
print(ts.resample('M').mean())  # 月度平均值
```

### Matplotlib
Matplotlib是Python的基础可视化库，提供了类似MATLAB的绘图API。

```python
import matplotlib.pyplot as plt
import numpy as np

# 基础线图
x = np.linspace(0, 2*np.pi, 100)
y = np.sin(x)
plt.figure(figsize=(10, 6))
plt.plot(x, y, label='sin(x)')
plt.title('Sine Wave')
plt.xlabel('x')
plt.ylabel('sin(x)')
plt.legend()
plt.grid(True)
plt.show()

# 多子图
fig, axs = plt.subplots(2, 2, figsize=(10, 8))
axs[0, 0].plot(x, np.sin(x))
axs[0, 0].set_title('Sine')
axs[0, 1].plot(x, np.cos(x))
axs[0, 1].set_title('Cosine')
axs[1, 0].plot(x, np.sin(2*x))
axs[1, 0].set_title('Sine 2x')
axs[1, 1].plot(x, np.cos(2*x))
axs[1, 1].set_title('Cosine 2x')
plt.tight_layout()
plt.show()

# 柱状图
categories = ['A', 'B', 'C', 'D', 'E']
values = [25, 40, 30, 55, 15]
plt.figure(figsize=(10, 6))
plt.bar(categories, values)
plt.title('Bar Chart')
plt.xlabel('Category')
plt.ylabel('Value')
plt.show()

# 散点图
x = np.random.rand(50)
y = np.random.rand(50)
colors = np.random.rand(50)
sizes = 1000 * np.random.rand(50)
plt.figure(figsize=(10, 6))
plt.scatter(x, y, c=colors, s=sizes, alpha=0.5)
plt.title('Scatter Plot')
plt.xlabel('X')
plt.ylabel('Y')
plt.show()
```

### Seaborn
Seaborn是基于Matplotlib的高级可视化库，提供了美观的默认样式和复杂的统计图表。

```python
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# 设置主题
sns.set_theme(style="whitegrid")

# 创建示例数据
tips = sns.load_dataset("tips")

# 分类散点图
plt.figure(figsize=(10, 6))
sns.stripplot(x="day", y="total_bill", data=tips, jitter=True)
plt.title('Strip Plot')
plt.show()

# 箱型图
plt.figure(figsize=(10, 6))
sns.boxplot(x="day", y="total_bill", data=tips)
plt.title('Box Plot')
plt.show()

# 小提琴图
plt.figure(figsize=(10, 6))
sns.violinplot(x="day", y="total_bill", hue="sex", data=tips, split=True)
plt.title('Violin Plot')
plt.show()

# 成对关系图
plt.figure(figsize=(10, 8))
sns.pairplot(tips, hue="sex")
plt.suptitle('Pair Plot', y=1.02)
plt.show()

# 热力图
corr = tips.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()
```

### Scikit-learn
Scikit-learn是Python的机器学习库，提供了各种算法和数据预处理工具。

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd

# 加载示例数据
iris = load_iris()
X = iris.data
y = iris.target

# 数据分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 数据预处理
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 模型训练
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

# 模型评估
y_pred = model.predict(X_test_scaled)
print(classification_report(y_test, y_pred, target_names=iris.target_names))

# 混淆矩阵
conf_mat = confusion_matrix(y_test, y_pred)
print(conf_mat)

# 特征重要性
feature_importance = pd.DataFrame({
    'feature': iris.feature_names,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)
print(feature_importance)
```

## 数据分析流程

### 1. 数据加载与检查
```python
import pandas as pd

# 加载数据
df = pd.read_csv('data.csv')
# 或从数据库
# import sqlite3
# conn = sqlite3.connect('database.sqlite')
# df = pd.read_sql_query("SELECT * FROM table_name", conn)

# 基本检查
print(df.shape)  # 行数和列数
print(df.columns)  # 列名
print(df.dtypes)  # 数据类型
print(df.head())  # 前几行
print(df.tail())  # 后几行
print(df.describe())  # 统计摘要
print(df.info())  # 整体信息，包括缺失值

# 检查缺失值
print(df.isnull().sum())  # 各列缺失值计数
print(df.isnull().sum().sum())  # 总缺失值计数
```

### 2. 数据清洗与预处理
```python
# 处理缺失值
df_filled = df.fillna({'数值列': df['数值列'].mean(), 
                       '分类列': df['分类列'].mode()[0]})
# 或直接删除
df_dropped = df.dropna(subset=['重要列'])

# 处理重复数据
print(df.duplicated().sum())  # 检查重复行数
df_unique = df.drop_duplicates()  # 删除重复行

# 数据类型转换
df['日期列'] = pd.to_datetime(df['日期列'])
df['数值列'] = pd.to_numeric(df['数值列'], errors='coerce')
df['分类列'] = df['分类列'].astype('category')

# 异常值处理
Q1 = df['数值列'].quantile(0.25)
Q3 = df['数值列'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
df_filtered = df[(df['数值列'] >= lower_bound) & (df['数值列'] <= upper_bound)]

# 数据规范化/标准化
from sklearn.preprocessing import StandardScaler, MinMaxScaler
scaler = StandardScaler()  # 或 MinMaxScaler()
df['标准化列'] = scaler.fit_transform(df[['数值列']])
```

### 3. 探索性数据分析 (EDA)
```python
import matplotlib.pyplot as plt
import seaborn as sns

# 单变量分析
plt.figure(figsize=(10, 6))
# 数值变量的分布
sns.histplot(df['数值列'], kde=True)
plt.title('数值分布')
plt.show()

# 分类变量的计数
plt.figure(figsize=(12, 6))
sns.countplot(y='分类列', data=df, order=df['分类列'].value_counts().index)
plt.title('分类变量计数')
plt.show()

# 相关性分析
numeric_df = df.select_dtypes(include=['float64', 'int64'])
corr = numeric_df.corr()
plt.figure(figsize=(12, 10))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('相关性热力图')
plt.show()

# 双变量分析
plt.figure(figsize=(10, 6))
sns.scatterplot(x='特征1', y='特征2', hue='目标变量', data=df)
plt.title('特征1 vs 特征2 by 目标变量')
plt.show()

# 分组分析
grouped = df.groupby('分类变量')['数值变量'].agg(['mean', 'median', 'std'])
print(grouped)
```

### 4. 特征工程
```python
# 创建衍生特征
df['日期列_年'] = df['日期列'].dt.year
df['日期列_月'] = df['日期列'].dt.month
df['日期列_日'] = df['日期列'].dt.day
df['日期列_星期'] = df['日期列'].dt.dayofweek

# 特征交互
df['特征1_特征2'] = df['特征1'] * df['特征2']
df['特征1_特征2_比'] = df['特征1'] / (df['特征2'] + 1e-10)  # 避免除零

# 特征编码
# 独热编码
df_encoded = pd.get_dummies(df, columns=['分类特征1', '分类特征2'])

# 标签编码
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['分类特征_编码'] = le.fit_transform(df['分类特征'])

# 数据降维
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(numeric_df)
# 可视化降维结果
plt.figure(figsize=(10, 8))
plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.7)
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('PCA降维结果')
plt.show()
```

## 常见用例

### 时间序列分析
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima.model import ARIMA

# 创建时间序列数据
dates = pd.date_range(start='2020-01-01', periods=365, freq='D')
np.random.seed(42)
values = np.cumsum(np.random.randn(365)) + np.sin(np.linspace(0, 12*np.pi, 365)) * 10
ts = pd.Series(values, index=dates)

# 可视化时间序列
plt.figure(figsize=(12, 6))
plt.plot(ts)
plt.title('时间序列数据')
plt.xlabel('日期')
plt.ylabel('值')
plt.grid(True)
plt.show()

# 重采样 - 月度平均
monthly_mean = ts.resample('M').mean()
plt.figure(figsize=(12, 6))
plt.plot(monthly_mean)
plt.title('月度平均')
plt.xlabel('日期')
plt.ylabel('月平均值')
plt.grid(True)
plt.show()

# 移动平均
rolling_mean = ts.rolling(window=7).mean()
plt.figure(figsize=(12, 6))
plt.plot(ts, label='原始数据')
plt.plot(rolling_mean, label='7日移动平均')
plt.title('移动平均')
plt.xlabel('日期')
plt.ylabel('值')
plt.legend()
plt.grid(True)
plt.show()

# 时间序列分解
decomposition = seasonal_decompose(ts, model='additive', period=30)
fig = decomposition.plot()
fig.set_size_inches(14, 10)
plt.tight_layout()
plt.show()

# ARIMA模型预测
model = ARIMA(ts, order=(5, 1, 2))
model_fit = model.fit()
forecast = model_fit.forecast(steps=30)
plt.figure(figsize=(12, 6))
plt.plot(ts, label='原始数据')
plt.plot(pd.Series(forecast, index=pd.date_range(start=ts.index[-1]+pd.Timedelta(days=1), periods=30)), label='预测')
plt.title('ARIMA预测')
plt.xlabel('日期')
plt.ylabel('值')
plt.legend()
plt.grid(True)
plt.show()
```

### 地理空间数据可视化
```python
# 安装必要的库: pip install geopandas folium
import geopandas as gpd
import folium
import pandas as pd
import matplotlib.pyplot as plt

# 读取地理空间数据
# world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))

# 创建示例数据
world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))

# 简单地图可视化
plt.figure(figsize=(15, 10))
world.plot(column='pop_est', cmap='OrRd', legend=True)
plt.title('世界人口分布')
plt.axis('off')
plt.show()

# 使用Folium创建交互式地图
m = folium.Map(location=[0, 0], zoom_start=2)

# 添加choropleth图层
folium.Choropleth(
    geo_data=world.__geo_interface__,
    name='choropleth',
    data=world,
    columns=['name', 'pop_est'],
    key_on='feature.properties.name',
    fill_color='YlOrRd',
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name='人口估计'
).add_to(m)

folium.LayerControl().add_to(m)
# m.save('world_population.html')
```

### 自然语言处理 (简单示例)
```python
# 安装必要的库: pip install nltk scikit-learn wordcloud
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from wordcloud import WordCloud

# 下载NLTK资源
# nltk.download('punkt')
# nltk.download('stopwords')
# nltk.download('wordnet')

# 示例文本数据
texts = [
    "Python is a great programming language for data analysis.",
    "Data scientists use Python for machine learning and visualization.",
    "Natural language processing is an important field in AI.",
    "Text analysis helps us understand patterns in written content."
]
# 文本预处理函数
def preprocess_text(text):
    # 转为小写
    text = text.lower()
    # 移除特殊字符和数字
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    # 分词
    tokens = word_tokenize(text)
    # 移除停用词
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    # 词形还原
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return ' '.join(tokens)

# 应用预处理
processed_texts = [preprocess_text(text) for text in texts]

# 创建词频矩阵
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(processed_texts)
df_bow = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())
print("词频矩阵:")
print(df_bow)

# 创建TF-IDF矩阵
tfidf_vectorizer = TfidfVectorizer()
X_tfidf = tfidf_vectorizer.fit_transform(processed_texts)
df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())
print("\nTF-IDF矩阵:")
print(df_tfidf)

# 生成词云
all_text = ' '.join(processed_texts)
wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=100).generate(all_text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('词云')
plt.show()
```

## 资源和扩展阅读

### 推荐书籍
- Python for Data Analysis by Wes McKinney
- Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow by Aurélien Géron
- Data Science from Scratch by Joel Grus

### 在线课程
- DataCamp - Python数据科学课程
- Coursera - IBM Data Science Professional Certificate
- edX - Python for Data Science

### 有用的库
- pandas-profiling: 一行代码生成数据报告
- vaex: 大数据处理库
- dask: 分布式计算框架
- plotly: 交互式可视化
- streamlit: 快速构建数据应用 